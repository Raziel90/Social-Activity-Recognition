{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from social_activity_recognition import load_dataset\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = load_dataset('./skeleton_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.33910258 5.94124143 6.44866218 1.        ]\n",
      " [2.19935787 2.6332197  4.19648699 1.        ]\n",
      " [2.67482167 4.48465942 4.41553324 1.        ]\n",
      " [4.94199166 5.09126741 3.80768768 1.        ]\n",
      " [1.62545096 3.269066   2.42920742 1.        ]\n",
      " [3.47739974 3.55563319 1.05072333 1.        ]\n",
      " [4.2699648  5.734872   6.44866117 1.        ]\n",
      " [2.2327765  4.13409646 4.19648716 1.        ]\n",
      " [2.48558321 3.45361392 4.14062077 1.        ]\n",
      " [4.94199166 4.97634437 5.36950197 1.        ]\n",
      " [1.62545096 3.31856771 2.42922204 1.        ]\n",
      " [3.47739974 3.28754654 5.77209436 1.        ]\n",
      " [4.19996664 1.48222492 6.0442382  1.        ]\n",
      " [2.26544406 4.28438812 4.31552155 1.        ]\n",
      " [2.29009699 5.42599847 4.12821733 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "data_size = DS[(DS['activity']==1) & (DS['session']==1)]['user1'].values[0].shape\n",
    "data_points = np.concatenate([DS[(DS['activity']==1) & (DS['session']==1)]['user1'].values[0],np.ones((data_size[0],1,15))],axis=1)\n",
    "#print(data_points)\n",
    "random_transf = np.concatenate([np.concatenate([np.eye(3),np.zeros((1,3))],axis=0),np.array([2,3,4,1])[:,np.newaxis]],axis=1) #np.random.normal(size=(3,3))\n",
    "#random_transf = [np.concatenate([np.eye(3),np.zeros((1,3))],axis=0).shape,np.array([2,3,4,1])[:,np.newaxis].shape]\n",
    "random_transf\n",
    "#random_transf\n",
    "print(np.matmul(random_transf,data_points[0])[0:4,:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1793, 4, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_points.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transformation_layer(output_point_series, subname=''):\n",
    "    \n",
    "    Transform = tf.Variable(initial_value=tf.truncated_normal(shape=(output_point_series,3,3),stddev=1e-3,dtype=tf.float32),trainable=True,dtype=tf.float32)\n",
    "    Translation = tf.Variable(initial_value=tf.truncated_normal(shape=(output_point_series,3,1),stddev=1e-2,dtype=tf.float32),trainable=True,dtype=tf.float32)\n",
    "    Last_row = tf.Variable(initial_value=np.concatenate([np.zeros((output_point_series,1,3)),np.ones(((output_point_series,1,1)))],axis=2),\n",
    "                           trainable=False,dtype=tf.float32)\n",
    "    return tf.concat([tf.concat([Transform, Translation],axis=2),Last_row],axis=1,name='Transform_matrix' + subname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes must be equal rank, but are 1 and 2 for 'transformed1_user1' (op: 'BatchMatMul') with input shapes: [50,4,4], [?,1,4,15].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/venv_data_science/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1588\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1589\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1590\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes must be equal rank, but are 1 and 2 for 'transformed1_user1' (op: 'BatchMatMul') with input shapes: [50,4,4], [?,1,4,15].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-18ba6cc0d680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mscene_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_transformation_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_point_series\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscene_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scene'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtransformed1_user1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual_transform1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser1_ph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'transformed1_user1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mtransformed1_user2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual_transform1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser2_ph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'transformed1_user2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_data_science/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1974\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m       return gen_math_ops.batch_mat_mul(\n\u001b[0;32m-> 1976\u001b[0;31m           a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n\u001b[0m\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m     \u001b[0;31m# Neither matmul nor sparse_matmul support adjoint, so we conjugate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_data_science/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[0madj_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adj_y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 1236\u001b[0;31m         \"BatchMatMul\", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)\n\u001b[0m\u001b[1;32m   1237\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_data_science/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_data_science/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3412\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3413\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3414\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_data_science/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1754\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1755\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1756\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1757\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_data_science/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1590\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes must be equal rank, but are 1 and 2 for 'transformed1_user1' (op: 'BatchMatMul') with input shapes: [50,4,4], [?,1,4,15]."
     ]
    }
   ],
   "source": [
    "n_classes = 8\n",
    "ind_channels = [50,100]\n",
    "scene_channels = [30]\n",
    "fc_sizes = [100]\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default() as g:\n",
    "    \n",
    "    \n",
    "    \n",
    "    user1_ph = tf.placeholder(shape=(None,1,4,15),dtype=tf.float32)\n",
    "    user2_ph = tf.placeholder(shape=(None,1,4,15),dtype=tf.float32)\n",
    "    \n",
    "    label_ph = tf.placeholder(shape=(None,1,4,15),dtype=tf.float32)\n",
    "    \n",
    "    individual_transform1 = make_transformation_layer(output_point_series=ind_channels[0], subname='individual_1')\n",
    "    individual_transform2 = make_transformation_layer(output_point_series=ind_channels[1], subname='individual_2')\n",
    "    scene_transform = make_transformation_layer(output_point_series=scene_channels[0], subname='scene')\n",
    "    \n",
    "    transformed1_user1 = tf.matmul(individual_transform1, user1_ph, name='transformed1_user1')\n",
    "    transformed1_user2 = tf.matmul(individual_transform1, user2_ph, name='transformed1_user2')\n",
    "    \n",
    "    transformed2_user1 = tf.matmul(individual_transform1, transformed1_user1, name='transformed2_user1')\n",
    "    transformed2_user2 = tf.matmul(individual_transform1, transformed1_user2, name='transformed2_user2')\n",
    "    \n",
    "    scene_pts = tf.concat([transformed2_user1,transformed2_user2],axis=3)\n",
    "    \n",
    "    transformed_scene = tf.matmul(scene_transform, scene_pts, name='transformed_scene')\n",
    "    \n",
    "    flattened_points = tf.layers.flatten(transformed_scene, name=\"flattened_points\")\n",
    "    \n",
    "    fc_out_1 = tf.contrib.layers.fully_connected(\n",
    "        inputs=flattened_points,\n",
    "        num_outputs=fc_sizes[0],\n",
    "        activation_fn=tf.nn.relu(),\n",
    "        trainable=True\n",
    "    )\n",
    "    \n",
    "    fc_final = tf.contrib.layers.fully_connected(\n",
    "        inputs=fc_out_1,\n",
    "        num_outputs=n_classes,\n",
    "        activation_fn=tf.nn.relu(),\n",
    "        trainable=True\n",
    "    )\n",
    "    \n",
    "    prediction = tf.nn.softmax(logits=fc_final)\n",
    "    \n",
    "    \n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        labels=tf.one_hot(label_ph, depth=n_classes),\n",
    "        logits=fc_final)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "    \n",
    "    train_step = optimizer.minimize(tf.reduce_mean(loss))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_per_session=[]\n",
    "for s in range(1,len(DS['session'].unique())+1):\n",
    "    temp1 = []\n",
    "    temp2 = []\n",
    "    for a in range(1,len(DS['activity'].unique())+1):\n",
    "        mask = (DS['activity']==a) & (DS['session']!=s)\n",
    "        #print(s,a,DS[mask]['user1'].values[0].shape,DS[mask]['user2'].values[0].shape)\n",
    "        v_cat = np.concatenate([DS[mask]['user1'].values[0], DS[mask]['user2'].values[0]],axis=0)\n",
    "        temp1 += [v_cat.max(axis=2).max(axis=0)]\n",
    "        temp2 += [v_cat.min(axis=2).min(axis=0)]\n",
    "        #print(DS[mask]['user1'].values)\n",
    "        \n",
    "    min_max_per_session += [(np.concatenate(temp1).min(axis=0),np.concatenate(temp2).max(axis=0))]\n",
    "    \n",
    "#min_max_per_session\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range(1,len(DS['session'].unique())+1):\n",
    "    for a in range(1,len(DS['activity'].unique())+1):\n",
    "        mask = (DS['activity']==a) & (DS['session']!=s)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
